{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU avialible: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'ConfigProto'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5c885c2312d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInteractiveSession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_growth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mper_process_gpu_memory_fraction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'ConfigProto'"
     ]
    }
   ],
   "source": [
    " ## Deep Learning Sentiment Analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "import joblib\n",
    "import os\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import json\n",
    "import cloudpickle\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from multiprocessing import cpu_count, Pool\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from itertools import chain\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing.sequence import skipgrams\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Embedding, Dropout, Reshape, Activation, Input, Flatten, Dense, RepeatVector, BatchNormalization, LSTM, RepeatVector, MaxPooling1D,GlobalMaxPool1D, Conv1D, GRU, Bidirectional, Concatenate\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import Dot\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "print('GPU avialible: {}'.format(tf.config.list_physical_devices('GPU')))\n",
    "pd.options.display.width = 500\n",
    "\n",
    "import pandas as pd\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "run_config = tf.contrib.learn.RunConfig(session_config=config)\n",
    "\n",
    "\n",
    "n_embedding_dims = 50\n",
    "\n",
    "drop_rate = .2\n",
    "num_filters = 25\n",
    "kernal_size = 3\n",
    "\n",
    "\n",
    "## load data\n",
    "path = '../data/names.txt'\n",
    "with open(path, 'r') as f:\n",
    "    docs = f.readlines()\n",
    "docs = [d.strip() for d in docs]\n",
    "\n",
    "# fit the tokenizer\n",
    "tokenizer = Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(docs)\n",
    "vocab_size = len(list(tokenizer.index_word.items()))\n",
    "max_len = 20\n",
    "\n",
    "print('max_len {0} vocab_size {1}'.format(max_len, vocab_size))\n",
    "#\n",
    "def data_gen(docs, n_batches=10, batch_size=10):\n",
    "    n_docs = len(docs)\n",
    "    sample_index = np.arange(batch_size, n_docs- (batch_size + int(batch_size/2)))\n",
    "    for _ in range(n_batches):\n",
    "        i = np.random.choice(sample_index, 1)[0]\n",
    "        in_box_docs = docs[i:i+batch_size]\n",
    "        out_box_docs = docs[i-int(batch_size/2):i] + docs[i+batch_size:i + batch_size + int(batch_size/2)]\n",
    "        in_box_array = np.array(pad_sequences(tokenizer.texts_to_sequences(in_box_docs), maxlen=max_len))\n",
    "        out_box_array = np.array(pad_sequences(tokenizer.texts_to_sequences(out_box_docs), maxlen=max_len))\n",
    "        x = np.concatenate([in_box_array, in_box_array], axis=0)\n",
    "        x_aux = np.concatenate([in_box_array, out_box_array], axis=0)\n",
    "        y = np.array([1] * in_box_array.shape[0] + [0] * out_box_array.shape[0])\n",
    "        assert x_aux.shape[0] == x.shape[0]\n",
    "        assert y.shape[0] == x.shape[0]\n",
    "        yield [x, x_aux], y\n",
    "(x, x_aux), y = next(data_gen(docs))\n",
    "print(x.shape, x_aux.shape, y.shape)\n",
    "\n",
    "\n",
    "def get_model():\n",
    "\n",
    "    inputs = Input(shape=(max_len,),  name='input')\n",
    "    embedding_layer =  Embedding(vocab_size+ 1, n_embedding_dims,\n",
    "                                 input_length=max_len,\n",
    "                                 trainable=True)(inputs)\n",
    "    drop1 = Dropout(drop_rate, name = \"drop\")(embedding_layer)\n",
    "    conv1 = Conv1D(num_filters, kernel_size=kernal_size, activation='relu', name='conv1')(drop1)\n",
    "    pool1 = GlobalMaxPool1D(name = \"pool\")(conv1)\n",
    "\n",
    "    inputs_aux = Input(shape=(max_len,),  name='input_aux')\n",
    "    embedding_layer_aux =  Embedding(vocab_size+ 1, n_embedding_dims,\n",
    "                                 input_length=max_len,\n",
    "                                 trainable=True)(inputs_aux )\n",
    "    drop1_aux = Dropout(drop_rate, name = \"drop_aux\")(embedding_layer_aux)\n",
    "    conv1_aux = Conv1D(num_filters, kernel_size=kernal_size, activation='relu', name='conv_aux')(drop1_aux )\n",
    "    pool1_aux = GlobalMaxPool1D(name = \"pool_aux\")(conv1_aux)\n",
    "\n",
    "\n",
    "    merge = Dot(axes=1)([pool1,pool1_aux])\n",
    "\n",
    "\n",
    "    d1 = Dense(100,  activation = \"relu\", name = \"hidden\")(merge)\n",
    "    drop2 = Dropout(drop_rate, name=  \"drop2\")(d1)\n",
    "    act1 = Activation('relu', name = \"activ_solo\")(drop2)  ## weird that the activation is stack on a dropout layr\n",
    "    outputs = Dense(1, activation='sigmoid', name='sigmoidOutput')(act1)\n",
    "    model = Model(inputs=[inputs,inputs_aux],  outputs=outputs, name='MatchingNamesClassifier')\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    model = get_model()\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "\n",
    "model = get_model()\n",
    "print(model.summary())\n",
    "\n",
    "weights_path = \"models/weights_best.hdf5\"\n",
    "\n",
    "# save only the best weights\n",
    "checkpoint = ModelCheckpoint(weights_path ,mode='max' ,monitor='val_auc', verbose=1, save_best_only=True)\n",
    "\n",
    "learning_rate = .0004\n",
    "\n",
    "#update the optimizer learning rate\n",
    "K.set_value(model.optimizer.lr,learning_rate)\n",
    "\n",
    "lrPlateauReductionFactor = .5\n",
    "lrMin = 0.000001\n",
    "\n",
    "# reduces learning rate on performance platu\n",
    "lrCheckPoint = ReduceLROnPlateau(monitor =  'val_loss', factor=lrPlateauReductionFactor, min=lrMin)\n",
    "\n",
    "# stops training whenmodel fails to improve\n",
    "esm =  EarlyStopping(patience=5, monitor='val_auc',mode='max')\n",
    "\n",
    "\n",
    "n_epochs = 100\n",
    "n_steps_per_epoch = 10\n",
    "batch_size = 32\n",
    "\n",
    "train_docs, test_docs = train_test_split(docs)\n",
    "\n",
    "train_gen = data_gen(train_docs, n_batches=n_epochs * n_steps_per_epoch, batch_size=batch_size)\n",
    "test_gen = data_gen(test_docs, n_batches=n_epochs * n_steps_per_epoch, batch_size=batch_size * 2)\n",
    "model.fit(train_gen,\n",
    "                    epochs=n_epochs,\n",
    "                    steps_per_epoch= n_steps_per_epoch,\n",
    "                    validation_data = test_gen,\n",
    "                    validation_steps = n_steps_per_epoch,\n",
    "                    callbacks=[esm, lrCheckPoint, checkpoint], shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
